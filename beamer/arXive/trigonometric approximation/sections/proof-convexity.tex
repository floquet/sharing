% \input{\pathsections "proof-convexity"}

\begin{thm}[Convexity of least squares minimizers]

Given a matrix $\mathbf{A}\in\mathbb{C}^{m\times n}_{\rho}$ with rank $\paren{\rho\le n}$, and a data vector $b\in\mathbb{C}^{m}$, then $\chi$, the set of least squares minimizers,
%
\begin{equation*}
	\chi = \argmin_{x\in\mathbb{C}^{n}} \normt{\mathbf{A}\,x-b},
\end{equation*}
%
is a convex set.

\label{thm:theory convex set}
\end{thm}

%   +   +   +   +   +   +   +   +   +   +
\begin{proof}

%
Take two elements $x_{1}, x_{2} \in \chi$ and a variation parameter $\lambda\in\brac{0,1}$. Establish that the linear combination is also in the set of minimizers:
%
\begin{equation}
	\lambda x_{1} + \paren{1-\lambda} x_{2}\in\chi
\label{eq:convexity premise}
\end{equation}
%
Use the fact that $b= \lambda b + (1-\lambda) b$ and triangle inequality to show
\begin{equation}
	\begin{split}
		\normts{\mathbf{A}\paren{\lambda x_{1} + \paren{1-\lambda} x_{2}} - b} \le
		\lambda \normts{\mathbf{A}\,x_{1} - b} + \paren{1-\lambda}\normts{\mathbf{A}\,x_{2} - b}
	\end{split}
\label{eq:theory convex membership}
\end{equation}
%
Because the $x$ variables are minimizers, the norms achieve the minimum value (least total squared error) $t^{2}$.
%
\begin{equation}
	\lambda \normts{\mathbf{A}\,x_{1} - b} + \paren{1-\lambda}\normts{\mathbf{A}\,x_{2} - b} =
	\lambda t^{2} + \paren{1-\lambda}t^{2} = t^{2}
%\label{eq:}
\end{equation}
%
From which we conclude
%
\begin{equation}
	\normts{\mathbf{A}\paren{\lambda x_{1} + \paren{1-\lambda} x_{2}} - b} = t^{2}, \ \forall \lambda \in \brac{0,1}
%\label{eq:}
\end{equation}
%
thereby establishing the premise in equation \eqref{eq:theory convex membership}.
%
\end{proof}


\endinput %   =   =   =   =   =   =   =   =   =   =   =   =   =   =